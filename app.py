import cv2
import numpy as np
import os
import math
import time
import datetime
import threading
import smtplib
import requests
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.image import MIMEImage
from collections import deque
from flask import Flask, render_template, Response, jsonify
from ultralytics import YOLO

# ================= C·∫§U H√åNH H·ªÜ TH·ªêNG & TH√îNG B√ÅO =================

# 1. C·∫•u h√¨nh Model & Video
MODEL_PATH = "models/Yolov8s-50epochs.engine"
VIDEO_PATHS = ["videos/firevid2.mp4", "videos/nonfirevid1.mp4", "videos/nonfirevid2.mp4", "videos/nonfirevid3.mp4"]
OUTPUT_DIR = "runs/alerts"
CONF_THRESHOLD = 0.45
CLASS_ID_FIRE = 0

# 2. C·∫•u h√¨nh Telegram (B·∫°n c·∫ßn ƒëi·ªÅn token c·ªßa b·∫°n)
TELEGRAM_ENABLE = True
TELEGRAM_TOKEN = "YOUR_TELEGRAM_BOT_TOKEN" 
TELEGRAM_CHAT_ID = "YOUR_CHAT_ID"

# 3. C·∫•u h√¨nh Email (D√πng App Password n·∫øu l√† Gmail)
EMAIL_ENABLE = True
EMAIL_SENDER = "your_email@gmail.com"
EMAIL_PASSWORD = "your_app_password"  # Kh√¥ng d√πng m·∫≠t kh·∫©u ƒëƒÉng nh·∫≠p, d√πng App Password
EMAIL_RECEIVER = "admin_email@gmail.com"

# 4. C·∫•u h√¨nh Cooldown (Ch·ªëng Spam)
NOTIFICATION_COOLDOWN = 60 # Ch·ªâ g·ª≠i c·∫£nh b√°o m·ªói 60 gi√¢y cho 1 camera

# C·∫•u h√¨nh Grid View
RESIZE_W = 640
RESIZE_H = 360
GAP_SIZE = 4
GAP_COLOR = (20, 20, 20)

# C·∫•u h√¨nh quay video
FPS_RECORD = 30
PRE_PADDING = 2 * FPS_RECORD
POST_PADDING = 3 * FPS_RECORD

os.makedirs(OUTPUT_DIR, exist_ok=True)
app = Flask(__name__)
model = YOLO(MODEL_PATH, task='detect')

# ================= MODULE TH√îNG B√ÅO (NOTIFICATION SYSTEM) =================
class NotificationSystem:
    @staticmethod
    def send_telegram(cam_id, image_frame):
        if not TELEGRAM_ENABLE: return
        try:
            url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto"
            # Encode ·∫£nh ƒë·ªÉ g·ª≠i
            _, img_encoded = cv2.imencode('.jpg', image_frame)
            files = {'photo': ('fire.jpg', img_encoded.tobytes())}
            data = {'chat_id': TELEGRAM_CHAT_ID, 'caption': f"üî• C·∫¢NH B√ÅO: Ph√°t hi·ªán L·ª¨A t·∫°i {cam_id}!"}
            requests.post(url, files=files, data=data)
            print(f"[TELEGRAM] ƒê√£ g·ª≠i c·∫£nh b√°o cho {cam_id}")
        except Exception as e:
            print(f"[L·ªñI TELEGRAM] {e}")

    @staticmethod
    def send_email(cam_id, image_frame, time_str):
        if not EMAIL_ENABLE: return
        try:
            msg = MIMEMultipart()
            msg['Subject'] = f"üî• FIRE ALERT: {cam_id} - {time_str}"
            msg['From'] = EMAIL_SENDER
            msg['To'] = EMAIL_RECEIVER

            text = MIMEText(f"H·ªá th·ªëng ph√°t hi·ªán nguy c∆° ch√°y t·∫°i {cam_id} v√†o l√∫c {time_str}.\nVui l√≤ng ki·ªÉm tra ngay.")
            msg.attach(text)

            # ƒê√≠nh k√®m ·∫£nh
            _, img_encoded = cv2.imencode('.jpg', image_frame)
            image = MIMEImage(img_encoded.tobytes(), name=f"fire_{cam_id}.jpg")
            msg.attach(image)

            # G·ª≠i mail qua SMTP Gmail
            with smtplib.SMTP_SSL('smtp.gmail.com', 465) as server:
                server.login(EMAIL_SENDER, EMAIL_PASSWORD)
                server.sendmail(EMAIL_SENDER, EMAIL_RECEIVER, msg.as_string())
            print(f"[EMAIL] ƒê√£ g·ª≠i mail c·∫£nh b√°o cho {cam_id}")
        except Exception as e:
            print(f"[L·ªñI EMAIL] {e}")

    @staticmethod
    def trigger_alerts(cam_id, frame):
        # Ch·∫°y trong lu·ªìng ri√™ng ƒë·ªÉ kh√¥ng l√†m lag video
        time_str = datetime.datetime.now().strftime("%H:%M:%S %d/%m/%Y")
        
        t1 = threading.Thread(target=NotificationSystem.send_telegram, args=(cam_id, frame))
        t2 = threading.Thread(target=NotificationSystem.send_email, args=(cam_id, frame, time_str))
        
        t1.start()
        t2.start()

# ================= CLASS X·ª¨ L√ù CAMERA (ƒê√É T·ªêI ∆ØU FPS) =================
class CameraAgent:
    def __init__(self, cam_id, source_path):
        self.cam_id = cam_id
        self.cap = cv2.VideoCapture(source_path)
        
        self.buffer = deque(maxlen=PRE_PADDING)
        self.is_recording = False
        self.recording_writer = None
        self.post_record_counter = 0
        self.current_filename = ""
        self.last_alert_time = 0 

        self.width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        self.height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        self.fps = self.cap.get(cv2.CAP_PROP_FPS) or 30

        # --- BI·∫æN T·ªêI ∆ØU FPS ---
        self.frame_count = 0
        self.DETECT_INTERVAL = 4  # Ch·ªâ detect m·ªói 4 frame (Detect 1, ngh·ªâ 3)
        self.last_boxes = []      # L∆∞u k·∫øt qu·∫£ detect c≈© ƒë·ªÉ v·∫Ω l·∫°i
        self.is_fire_detected = False

    def read_frame(self):
        ret, frame = self.cap.read()
        if not ret:
            self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
            ret, frame = self.cap.read()
        return ret, frame

    def process_logic(self, frame):
        self.frame_count += 1
        display_frame = frame.copy() # Frame g·ªëc ƒë·ªÉ l∆∞u video/v·∫Ω
        
        # --- T·ªêI ∆ØU 1: RESIZE TR∆Ø·ªöC KHI DETECT ---
        # Ch·ªâ resize ·∫£nh ƒë∆∞a v√†o AI, kh√¥ng resize ·∫£nh g·ªëc (ƒë·ªÉ video l∆∞u l·∫°i v·∫´n n√©t)
        # Resize v·ªÅ k√≠ch th∆∞·ªõc 640 ƒë·ªÉ YOLO x·ª≠ l√Ω nhanh nh·∫•t
        ai_frame = cv2.resize(frame, (640, 640)) 

        # --- T·ªêI ∆ØU 2: FRAME SKIPPING (Detect m·ªói N frame) ---
        if self.frame_count % self.DETECT_INTERVAL == 0:
            # Ch·∫°y YOLO tr√™n ·∫£nh ƒë√£ resize
            results = model(ai_frame, verbose=False, conf=CONF_THRESHOLD, iou=0.45, device=0)
            
            self.last_boxes = []
            self.is_fire_detected = False
            
            for r in results:
                boxes = r.boxes
                for box in boxes:
                    cls = int(box.cls[0])
                    if cls == CLASS_ID_FIRE:
                        self.is_fire_detected = True
                        # C·∫ßn t√≠nh t·ªâ l·ªá ƒë·ªÉ map box t·ª´ ·∫£nh 640x640 v·ªÅ ·∫£nh g·ªëc
                        scale_x = self.width / 640
                        scale_y = self.height / 640
                        
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy() # L·∫•y to·∫° ƒë·ªô
                        
                        # Scale to·∫° ƒë·ªô v·ªÅ k√≠ch th∆∞·ªõc th·∫≠t
                        real_box = (int(x1 * scale_x), int(y1 * scale_y), int(x2 * scale_x), int(y2 * scale_y))
                        self.last_boxes.append(real_box)
        
        # --- V·∫º L·∫†I C√ÅC BOX T·ª™ K·∫æT QU·∫¢ C≈® (HO·∫∂C M·ªöI) ---
        # D√π kh√¥ng ch·∫°y detect frame n√†y, ta v·∫´n v·∫Ω l·∫°i box c·ªßa l·∫ßn detect tr∆∞·ªõc
        for (x1, y1, x2, y2) in self.last_boxes:
            cv2.rectangle(display_frame, (x1, y1), (x2, y2), (0, 0, 255), 2)
            cv2.putText(display_frame, f"FIRE {self.cam_id}", (x1, y1 - 10), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)

        # --- LOGIC TH√îNG B√ÅO & GHI H√åNH (Gi·ªØ nguy√™n) ---
        current_timestamp = time.time()
        current_time_str = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")

        # D√πng bi·∫øn is_fire_detected ƒë√£ ƒë∆∞·ª£c cache
        if self.is_fire_detected:
            if current_timestamp - self.last_alert_time > NOTIFICATION_COOLDOWN:
                # Ch·∫°y thread g·ª≠i th√¥ng b√°o...
                NotificationSystem.trigger_alerts(self.cam_id, display_frame) # G·ª≠i ·∫£nh c√≥ v·∫Ω box
                self.last_alert_time = current_timestamp
                GlobalState.should_play_sound = True

        if not self.is_recording:
            self.buffer.append(frame) # L∆∞u frame g·ªëc s·∫°ch v√†o buffer
            if self.is_fire_detected:
                self.is_recording = True
                self.current_filename = f"{self.cam_id}_{current_time_str}.mp4"
                save_path = os.path.join(OUTPUT_DIR, self.current_filename)
                fourcc = cv2.VideoWriter_fourcc(*'mp4v')
                self.recording_writer = cv2.VideoWriter(save_path, fourcc, self.fps, (self.width, self.height))
                while self.buffer: self.recording_writer.write(self.buffer.popleft())
                self.recording_writer.write(frame)
                GlobalState.alerts.insert(0, {"cam": self.cam_id, "time": datetime.datetime.now().strftime("%H:%M:%S"), "file": self.current_filename})
        else:
            if self.is_fire_detected:
                self.post_record_counter = POST_PADDING
                self.recording_writer.write(frame)
            else:
                if self.post_record_counter > 0:
                    self.recording_writer.write(frame)
                    self.post_record_counter -= 1
                else:
                    self.is_recording = False
                    self.recording_writer.release()
                    self.recording_writer = None

        return display_frame
# ================= GLOBAL STATE =================
class GlobalState:
    cameras = []
    alerts = []
    should_play_sound = False # Bi·∫øn c·ªù ƒë·ªÉ b√°o hi·ªáu Web UI ph√°t √¢m thanh

# Kh·ªüi t·∫°o Camera
for i, path in enumerate(VIDEO_PATHS):
    if os.path.exists(path):
        GlobalState.cameras.append(CameraAgent(f"Cam_{i+1}", path))

def create_mosaic_frame(frames):
    n = len(frames)
    if n == 0: return None
    cols = math.ceil(math.sqrt(n))
    rows = math.ceil(n / cols)
    total_w = RESIZE_W * cols + GAP_SIZE * (cols + 1)
    total_h = RESIZE_H * rows + GAP_SIZE * (rows + 1)
    canvas = np.full((total_h, total_w, 3), GAP_COLOR, dtype=np.uint8)

    for r in range(rows):
        for c in range(cols):
            idx = r * cols + c
            if idx >= n: continue
            small_frame = cv2.resize(frames[idx], (RESIZE_W, RESIZE_H))
            x = GAP_SIZE + c * (RESIZE_W + GAP_SIZE)
            y = GAP_SIZE + r * (RESIZE_H + GAP_SIZE)
            canvas[y:y+RESIZE_H, x:x+RESIZE_W] = small_frame
    return canvas

def generate_feed():
    frame_count = 0
    start_time = time.time()
    current_fps = 0.0

    while True:
        frames_to_merge = []
        for cam in GlobalState.cameras:
            ret, raw = cam.read_frame()
            if ret: frames_to_merge.append(cam.process_logic(raw))
            else: frames_to_merge.append(np.zeros((RESIZE_H, RESIZE_W, 3), dtype=np.uint8))

        if frames_to_merge:
            mosaic = create_mosaic_frame(frames_to_merge)
            frame_count += 1
            elapsed = time.time() - start_time
            if elapsed >= 1.0:
                current_fps = frame_count / elapsed
                frame_count = 0
                start_time = time.time()
            
            cv2.putText(mosaic, f"FPS: {current_fps:.1f}", (15, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)
            ret, buffer = cv2.imencode('.jpg', mosaic)
            yield (b'--frame\r\n' b'Content-Type: image/jpeg\r\n\r\n' + buffer.tobytes() + b'\r\n')

# ================= FLASK ROUTER =================
@app.route('/')
def index(): return render_template('index.html')

@app.route('/video_feed')
def video_feed(): return Response(generate_feed(), mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/api/alerts')
def get_alerts():
    return jsonify(GlobalState.alerts[:15])

@app.route('/api/status')
def check_status():
    # API n√†y ƒë·ªÉ Web UI h·ªèi xem c√≥ c·∫ßn h√∫ c√≤i kh√¥ng
    play = GlobalState.should_play_sound
    if play:
        GlobalState.should_play_sound = False # Reset sau khi ƒë√£ b√°o
    return jsonify({"play_sound": play})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=False, threaded=True)